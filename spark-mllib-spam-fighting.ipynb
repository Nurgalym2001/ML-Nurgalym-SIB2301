{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек и модулей:\n",
    "### Импортируются необходимые библиотеки и модули, такие как os, sys, email_read_util и различные классы из pyspark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../chapter1')\n",
    "import email_read_util\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных:\n",
    "### Загружается набор данных \"2007 TREC Public Spam Corpus\" и распаковывается в директорию 'chapter1/datasets'. Проверяются пути к директориям 'data_dir' и 'labels_path'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../chapter1/datasets/trec07p/data/'\n",
    "LABELS_FILE = '../chapter1/datasets/trec07p/full/index'\n",
    "TRAINING_SET_RATIO = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение меток (labels):\n",
    "Читаются метки из файла 'index' и сохраняются в словаре labels, где ключ - это имя файла, а значение - метка (1 для 'ham' и 0 для других)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "# Read the labels.\n",
    "with open(LABELS_FILE) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, key = line.split()\n",
    "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение электронных писем:\n",
    "Функция read_email_files() считывает текст электронных писем и их метки, используя утилиту email_read_util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email_files():\n",
    "    X = []\n",
    "    y = [] \n",
    "    for i in range(len(labels)):\n",
    "        filename = 'inmail.' + str(i+1)\n",
    "        email_str = email_read_util.extract_email_text(\n",
    "            os.path.join(DATA_DIR, filename))\n",
    "        X.append(email_str)\n",
    "        y.append(labels[filename])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создается DataFrame df с полями 'id', 'email' и 'label' на основе считанных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = read_email_files()\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('id', IntegerType(), nullable=False),\n",
    "            StructField('email', StringType(), nullable=False),\n",
    "            StructField('label', DoubleType(), nullable=False)])\n",
    "\n",
    "df = spark.createDataFrame(zip(range(len(y)), X, y), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root\n",
    " |-- id: integer (nullable = false)\n",
    " |-- email: string (nullable = false)\n",
    " |-- label: double (nullable = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame разделяется на обучающую и тестовую выборки в соотношении 70% к 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([TRAINING_SET_RATIO, 1-TRAINING_SET_RATIO], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели:\n",
    "#### Создается конвейер pipeline, включающий токенизатор, векторизатор и классификатор случайного леса.\n",
    "#### Устанавливаются параметры для каждого этапа конвейера.\n",
    "#### Модель обучается на обучающей выборке с установленными параметрами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "vectorizer = CountVectorizer()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, vectorizer, rfc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramMap = {\n",
    "    tokenizer.inputCol: 'email',\n",
    "    tokenizer.outputCol: 'tokens',\n",
    "\n",
    "    vectorizer.inputCol: 'tokens',\n",
    "    vectorizer.outputCol: 'vectors',\n",
    "\n",
    "    rfc.featuresCol: 'vectors',\n",
    "    rfc.labelCol: 'label',\n",
    "    rfc.numTrees: 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(train, params=paramMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка модели:\n",
    "#### Делаются предсказания на тестовой выборке с помощью обученной модели.\n",
    "#### Вычисляются метрики оценки модели: площадь под ROC-кривой и площадь под кривой precision/recall.\n",
    "#### Выводятся значения метрик: \"Area under ROC curve score\" и \"Area under precision/recall curve score\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n",
    "pr_score = evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderPR'})\n",
    "roc_score = evaluator.evaluate(prediction, {evaluator.metricName: 'areaUnderROC'})\n",
    "\n",
    "print(\"Area under ROC curve score: {:.3f}\".format(roc_score))\n",
    "print(\"Area under precision/recall curve score: {:.3f}\".format(pr_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC curve score: 0.971\n",
    "Area under precision/recall curve score: 0.958\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты:\n",
    "#### Area under ROC curve score: 0.971\n",
    "#### Area under precision/recall curve score: 0.958\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Эти результаты представляют собой оценки производительности модели классификации на основе метрик ROC-кривой и кривой точности/полноты.\n",
    "\n",
    "1. **Площадь под ROC-кривой (Area under ROC curve)**:\n",
    "   - ROC-кривая показывает отношение между долей верных положительных и долей ложных положительных классификаций при варьировании порога для классификации.\n",
    "   - Площадь под ROC-кривой (Area under ROC curve, AUC-ROC) является мерой качества классификатора, при которой оценивается его способность различать между классами. Чем ближе AUC-ROC к 1, тем лучше производительность модели. Значение 0.971 указывает на высокий уровень производительности модели.\n",
    "\n",
    "2. **Площадь под кривой точности/полноты (Area under precision/recall curve)**:\n",
    "   - Кривая точности/полноты (Precision/Recall curve) показывает отношение между точностью (Precision) и полнотой (Recall) классификатора при различных порогах классификации.\n",
    "   - Площадь под этой кривой (Area under precision/recall curve, AUC-PR) также является мерой качества модели. Чем ближе AUC-PR к 1, тем лучше производительность модели. Значение 0.958 указывает на высокий уровень производительности модели по этой метрике.\n",
    "\n",
    "Таким образом, эти результаты свидетельствуют о том, что модель имеет хорошие характеристики в отношении как различения между классами, так и точности и полноты предсказаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
